{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "##'''convert dict type jsonl data to csv'''##\n",
    "###@SerajMostafa, Montana State University###\n",
    "########serajmostafa@montana.edu#############\n",
    "###############################<Â©sermost>####\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jsonLister():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def t_Parse(self, tweets):\n",
    "        retval = {\n",
    "            \"t_created_at\":tweets['created_at'],\n",
    "            \"t_id\":tweets['id'],\n",
    "            \"t_author_id\":tweets['author_id'],\n",
    "            \"t_text\":tweets['text'],\n",
    "#             \"t_lang\":tweets['lang'],\n",
    "            ## '''no <for> loop is implemented as public_metrics is a dictionary'''\n",
    "            \"t_rt_count\":tweets['public_metrics']['retweet_count'],\n",
    "            \"t_rp_count\":tweets['public_metrics']['reply_count'],\n",
    "            \"t_lk_count\":tweets['public_metrics']['like_count'],\n",
    "            \"t_qt_count\":tweets['public_metrics']['quote_count']\n",
    "#             \"annotations_start\":[],\n",
    "#             \"annotations_end\":[],\n",
    "#             \"url\":[],\n",
    "#             \"display_url\":[],\n",
    "            }\n",
    "        return retval\n",
    "    \n",
    "    def rt_Parse(self, data):\n",
    "        retval = {\n",
    "            \"rt_created_at\":data['created_at'],\n",
    "            \"rt_author_id\":data['author_id'],\n",
    "            \"rt_lang\":data['lang'],\n",
    "            \"rt_text\":data['text'],\n",
    "            \"rt_id\":data['id'],\n",
    "#             \"rt_convr_id\":data['conversation_id'],\n",
    "            \"rt_ref_tweet_id\":[],\n",
    "            \"rt_ref_tweet_type\":[],\n",
    "#             \"rt_annotations_start\":[],\n",
    "#             \"rt_annotations_end\":[],\n",
    "#             \"rt_url\":[],\n",
    "#             \"rt_display_url\":[],\n",
    "             ##'''no <for> loop is implemented as public_metrics is a dictionary'''\n",
    "            \"rt_rt_count\":data['public_metrics']['retweet_count'],\n",
    "            \"rt_rp_count\":data['public_metrics']['reply_count'],\n",
    "            \"rt_lk_count\":data['public_metrics']['like_count'],\n",
    "            \"rt_qt_count\":data['public_metrics']['quote_count']\n",
    "            }\n",
    "        \n",
    "        if \"referenced_tweets\" in data:\n",
    "            for items in data['referenced_tweets']:\n",
    "                retval['rt_ref_tweet_id'].append(items['id'])\n",
    "                retval['rt_ref_tweet_type'].append(items['type'])\n",
    "\n",
    "#         if \"entities\" in dataItem:\n",
    "#             if \"annotations\" in dataItem['entities']:\n",
    "#                 for annotation in dataItem['entities']['annotations']:\n",
    "#                     if \"start\" in annotation:\n",
    "#                         retval['rt_annotations_start'].append(annotation['start'])\n",
    "#                         retval['rt_annotations_end'].append(annotation['end'])\n",
    "\n",
    "#             if \"urls\" in dataItem['entities']:\n",
    "#                 for url in dataItem['entities']['urls']:\n",
    "#                     if \"url\" in url:\n",
    "#                         retval['rt_url'].append(url['url'])\n",
    "#                     if \"display_url\" in url:\n",
    "#                         retval['rt_display_url'].append(url['display_url'])\n",
    "            \n",
    "        return retval\n",
    "    \n",
    "    ## Only required when working with <user>    \n",
    "    def user_Parse(self, user):\n",
    "    ## '''this block can take data manually like in other methods, however the following dict trick gets them directly as it is in dict'''\n",
    "#         retval = {\n",
    "#             \"username\":user['username'],\n",
    "#             \"username\":user['id'],\n",
    "#             \"user_tweet_count\":users['public_metrics']['tweet_count'],\n",
    "#             \"author_id\":dataItem['author_id'],    \n",
    "#             }\n",
    "\n",
    "        if \"public_metrics\" in user:\n",
    "            for k, v in user['public_metrics'].items():\n",
    "                user[k] = v\n",
    "            del user['public_metrics']\n",
    "        return user\n",
    "\n",
    "    def parser(self, result):\n",
    "        t_parsed_list = []\n",
    "        # loop to work on 'tweets'\n",
    "        for tweet in result['includes']['tweets']:\n",
    "            element = self.t_Parse(tweet)\n",
    "            t_parsed_list.append(element)\n",
    "        t_parsed_list = pd.DataFrame(t_parsed_list)    \n",
    "#         t_parsed_list.to_csv('tweets.csv', encoding='utf-8', index=False)\n",
    "        \n",
    "        rt_parsed_list = []\n",
    "        # loop to work on 'data list'\n",
    "        for item in result['data']:\n",
    "            element = self.rt_Parse(item)\n",
    "            rt_parsed_list.append(element)\n",
    "        ## used <explode()> to create new rows for each id\n",
    "        rt_parsed_list = pd.DataFrame(rt_parsed_list).explode(column='rt_ref_tweet_id',ignore_index=True)\n",
    "        \n",
    "    ## only required when working with <user> fields\n",
    "        user_parsed_list = []\n",
    "        # loop to work on 'users'\n",
    "        for user in result['includes']['users']:\n",
    "            element = self.user_Parse(user)\n",
    "            user_parsed_list.append(element)\n",
    "        user_parsed_list = pd.DataFrame(user_parsed_list)\n",
    "#         user_parsed_list.to_csv('users.csv', encoding='utf-8', index=False) # \n",
    "\n",
    "        global a, b, c\n",
    "        a,b,c = rt_parsed_list, t_parsed_list, user_parsed_list\n",
    "        ## Merge the tables now based on ids' <author_id, id> etc.\n",
    "        table = rt_parsed_list.merge(t_parsed_list, left_on='rt_ref_tweet_id', right_on='t_id', how='left')\n",
    "#         table[['rt_id','rt_author_id','rt_ref_tweet_id','t_id','rt_author_id']].to_csv('test5_jan.csv', encoding='utf-8', index=False) ## this is for testing only\n",
    "        \n",
    "        \n",
    "        table = table.merge(user_parsed_list, left_on='rt_author_id', right_on='id', how='left')\n",
    "        \n",
    "#         table.to_csv('test_jan.csv', encoding='utf-8', index=False) ## this is for testing only\n",
    "#         table[['rt_author_id','t_author_id','t_rt_count']].to_csv('test3_jan.txt', encoding='utf-8', index=False) ## this is for testing only\n",
    "        \n",
    "        \n",
    "#         table.rt_ref_tweet_type = table.rt_ref_tweet_type.apply(','.join)\n",
    "        table.rt_created_at= pd.to_datetime(table.rt_created_at)\n",
    "        table.t_created_at= pd.to_datetime(table.t_created_at)\n",
    "        table.created_at= pd.to_datetime(table.created_at)\n",
    "#         table.to_csv('dec19_01-31_000000-235959.csv', encoding='utf-8', index=False)\n",
    "        \n",
    "        ## Other options [optional]\n",
    "#         table.rt_created_at= table.rt_created_at.apply(lambda x: x.split('.')[0].replace('T',' '))\n",
    "#         table = table.merge(user_parsed_list, how=\"left\", left_on='tt_author_id', right_on='id')\n",
    "#         table = table.drop_duplicates(\"tt_text\", keep='first')\n",
    "            \n",
    "#         print(t_parsed_list)\n",
    "#         print(\"-\"*100)\n",
    "#         print(rt_parsed_list)\n",
    "#         print(\"=\"*100)\n",
    "#         print(user_parsed_list)\n",
    "        \n",
    "        ### see customized prints to find match to do the merging    \n",
    "#         print(t_parsed_list[['t_id','t_author_id']])\n",
    "#         print(rt_parsed_list[['rt_ref_tweet_id','rt_id']])        #,'rt_author_id'\n",
    "#         print(user_parsed_list[['id','followers_count', 'following_count']])\n",
    "       \n",
    "        return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jl = jsonLister()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('jan20_24-27_000000-235959.jsonl', 'r', encoding=\"utf8\") as file:\n",
    "    res = []\n",
    "    for json_str in file:\n",
    "        result = json.loads(json_str)\n",
    "        res.append(jl.parser(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(res, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df\n",
    "## df[df[\"rt_created_at\"].between('2020-02-04 20:59:59','2020-02-04 23:59:59')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('jan20_24-27_000000-235959.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w = df[df[\"rt_created_at\"].between('2019-12-01 00:00:00','2019-12-01 23:59:59')]#df[(df['rt_created_at']> \"2019-12-01\") & (df['rt_created_at']< \"2019-12-03\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uw = df[['rt_author_id','t_author_id','rt_created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_uw.to_csv('dec_uw_1x24.tsv',index=False, sep='\\t') #.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
